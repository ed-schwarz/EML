{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 3: DCGAN for Flowers102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import scipy as sp\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flowers102 dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the size of the images is (500 x (something > 500)) or ((something > 500) x 500)\n",
    "# we choose the maximum crop to obtain squared images\n",
    "IMAGE_CROP = 500\n",
    "# fix the the image size according to the problem description\n",
    "IMAGE_SIZE = 256\n",
    "\n",
    "# specify data transformations\n",
    "transform = transforms.Compose([\n",
    "    # crop the images to be squared\n",
    "    transforms.CenterCrop(IMAGE_CROP),\n",
    "    # resize the images to the desired resolution\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    # convert images to tensors and scale \n",
    "    transforms.ToTensor(),\n",
    "    # normalize images to have values in [-1,1] in each channel\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "# read flower training dataset \n",
    "train_dataset = datasets.Flowers102(\n",
    "    root=\"data\", \n",
    "    split=\"train\",\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# read flower validation dataset \n",
    "val_dataset = datasets.Flowers102(\n",
    "    root=\"data\",\n",
    "    split=\"val\",\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# read flower test dataset \n",
    "test_dataset = datasets.Flowers102(\n",
    "    root=\"data\",\n",
    "    split=\"test\",\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# join all datasets into one as we want to select images from the whole dataset\n",
    "flower_dataset = torch.utils.data.ConcatDataset([train_dataset, val_dataset, test_dataset])\n",
    "\n",
    "print('Total number of image samples in dataset:',len(flower_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flower category dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read 'label : flower category' dictionary\n",
    "# note: class labels are in [0,1,...,101], in the the dictionary labels are in [1,2,...,102]\n",
    "with open('./data/flowers-102/flower-categories.json', 'r') as f:\n",
    "    label_to_flowername = json.load(f)\n",
    "\n",
    "# output the flower name for classlabel\n",
    "classlabel = 0\n",
    "flowername = label_to_flowername[str(classlabel+1)]\n",
    "print(classlabel,':',flowername)\n",
    "\n",
    "# reversed dictionary: switch label and flower name\n",
    "flowername_to_label= dict((v, k) for k, v in label_to_flowername.items()) \n",
    "\n",
    "# output the class label for flowername \n",
    "flowername = 'lotus'\n",
    "classlabel = int(flowername_to_label[flowername])-1\n",
    "print(flowername,':',classlabel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
